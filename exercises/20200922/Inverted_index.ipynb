{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an inverted index\n",
    "\n",
    "  - You are given a sample (1000 documents) from the [The Reuters-21578 data collection](http://www.daviddlewis.com/resources/testcollections/reuters21578/) in `data/reuters21578-000.xml`\n",
    "  - The code that parses the XML and extract a list of preprocessed terms (tokenized, lowercased, stopwords removed) is already given\n",
    "  - You are also given an `InvertedIndex` class that manages the posting lists operations\n",
    "  - Your task is to build an inverted index from the input collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from xml.dom import minidom\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = ['a', 'an', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'for', 'if', 'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or', 'such', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will', 'with']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stripping tags inside <> using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def striptags(text):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse input text and return a list of indexable terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(text):\n",
    "    terms = []\n",
    "    # Replace specific characters with space\n",
    "    chars = ['\\'', '.', ':', ',', '!', '?', '(', ')']\n",
    "    for ch in chars:\n",
    "        if ch in text:\n",
    "            text = text.replace(ch, ' ')\n",
    "\n",
    "    # Remove tags\n",
    "    text = striptags(text)\n",
    "\n",
    "    # Tokenization\n",
    "    for term in text.split():  # default behavior of the split is to split on one or more whitespaces\n",
    "        # Lowercasing\n",
    "        term = term.lower()\n",
    "        # Stopword removal\n",
    "        if term in STOPWORDS:\n",
    "            continue\n",
    "        terms.append(term)\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the input document collection\n",
    "\n",
    "  - The collection is given as a single XML file. \n",
    "  - Each document is inside `<REUTERS ...> </REUTERS>`.\n",
    "  - We extract the contents of the `<DATE>`, `<TITLE>`, and `<BODY>` tags.\n",
    "  - After each extracted document, the provided callback function is called and all document data is passed in a single dict argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_collection(input_file, callback):\n",
    "    xmldoc = minidom.parse(input_file)\n",
    "    # Iterate documents in the XML file\n",
    "    itemlist = xmldoc.getElementsByTagName('REUTERS')\n",
    "    doc_id = 0\n",
    "    for doc in itemlist:\n",
    "        doc_id += 1\n",
    "        date = doc.getElementsByTagName('DATE')[0].firstChild.nodeValue\n",
    "        # Skip documents without a title or body\n",
    "        if not (doc.getElementsByTagName('TITLE') and doc.getElementsByTagName('BODY')):\n",
    "            continue\n",
    "        title = doc.getElementsByTagName('TITLE')[0].firstChild.nodeValue\n",
    "        body = doc.getElementsByTagName('BODY')[0].firstChild.nodeValue\n",
    "        callback({\n",
    "            'doc_id': doc_id,\n",
    "            'date': date,\n",
    "            'title': title,\n",
    "            'body': body\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints a document's contents (used as a callback function passed to `process_collection`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_doc(doc):\n",
    "    if doc['doc_id'] <= 5:  # print only the first 5 documents\n",
    "        print('docID:', doc['doc_id'])\n",
    "        print('date:', doc['date'])\n",
    "        print('title:', doc['title'])\n",
    "        print('body:', doc['body'])\n",
    "        print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_collection('data/reuters21578-000.xml', print_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Complete the inverted index class\n",
    "\n",
    "  - The inverted index is an object with methods for adding and fetching postings.\n",
    "  - The data is stored in a map, where keys are terms and values are lists of postings.\n",
    "  - Each posting is an object that holds the doc_id and an optional payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Posting(object):\n",
    "    \n",
    "    def __init__(self, doc_id, payload=None):\n",
    "        self.doc_id = doc_id\n",
    "        self.payload = payload\n",
    "    \n",
    "    def get_doc_id(self):\n",
    "        return self.doc_id\n",
    "    \n",
    "    def get_payload(self):\n",
    "        return self.payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndex(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.index = {}\n",
    "    \n",
    "    def add_posting(self, term, doc_id, payload=None):\n",
    "        \"\"\"Adds a document to the posting list of a term.\"\"\"\n",
    "        # TODO: if term not in index, initialize empty posting list\n",
    "        # TODO: append new posting to the posting list\n",
    "\n",
    "    def get_postings(self, term):\n",
    "        \"\"\"Fetches the posting list for a given term.\"\"\"\n",
    "        # TODO: complete\n",
    "        return None\n",
    "\n",
    "    def get_terms(self):\n",
    "        \"\"\"Returns all unique terms in the index.\"\"\"\n",
    "        return self.index.keys() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_postings():\n",
    "    ind = InvertedIndex()\n",
    "    ind.add_posting('term', 1, 1)\n",
    "    ind.add_posting('term', 2, 4)\n",
    "    # Testing existing term\n",
    "    postings = ind.get_postings('term')\n",
    "    assert len(postings) == 2\n",
    "    assert postings[0].get_doc_id() == 1\n",
    "    assert postings[0].get_payload() == 1\n",
    "    assert postings[1].get_doc_id() == 2\n",
    "    assert postings[1].get_payload() == 4\n",
    "    # Testing non-existent term\n",
    "    assert ind.get_postings(\"xyx\") is None\n",
    "\n",
    "def test_vocabulary():\n",
    "    ind = InvertedIndex()\n",
    "    ind.add_posting('term1', 1)\n",
    "    ind.add_posting('term2', 1)\n",
    "    ind.add_posting('term3', 2)\n",
    "    ind.add_posting('term2', 3)\n",
    "    assert set(ind.get_terms()) == set(['term1', 'term2', 'term3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 2: Build an inverted index from the input collection\n",
    "\n",
    "**TODO**: Complete the code to index the entire document collection.  (The content for each document should be the title and body concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = InvertedIndex()\n",
    "\n",
    "def index_doc(doc):\n",
    "    text = doc['title'] + ' ' + doc['body']\n",
    "    terms = parse(text)  # list of terms in the document    \n",
    "    # TODO: index the document (add all terms with freqs using `ind.add_posting()`)\n",
    "    \n",
    "process_collection('data/reuters21578-000.xml', index_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Save the inverted index to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the inverted index to a file (`data/index.dat`). Use a simple text format with `termID docID1:freq1 docID2:freq2 ...` per line, e.g.,\n",
    "\n",
    "```\n",
    "xxx 1:1 2:1 3:2\n",
    "yyy 2:1 4:2\n",
    "zzz 1:3 3:1 5:2\n",
    "...\n",
    "```\n",
    "\n",
    "Implement this by (1) adding a `write_to_file(self, filename)` method to the `InvertedIndex` class and then (2) invoking that method in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (advanced, optional): Plot collection size against index size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a plot that compares the size of the document collection (bytes) against the size of the corresponding index (bytes) on the y-axis vs. with respect to the number of documents on the x-axis. You may use [Matplotlib](https://www.tutorialspoint.com/jupyter/jupyter_notebook_plotting.htm) for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "\n",
    "Please give (anonymous) feedback on this exercise by filling out [this form](https://forms.gle/2jPayczbFhEcC9K68)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
