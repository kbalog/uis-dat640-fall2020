{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity linking\n",
    "\n",
    "You are provided with the data from a knowledge graph and asked to annotate an input document using a general entity linking pipeline approach, consisting of mention detection, candidate selection, and disambiguation steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "import pytest\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Mention detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given an excerpt from a surface form dictionary in the format `SF_DICT[mention][entity] = count`, where `count` refers to the number of times `mention` was linked to `entity` in a given training corpus.\n",
    "The total count of linked occurrences of a mention is given as the key `_total` (i.e., this is the number of times mention was linked to any entity in the training corpus).\n",
    "Note that not all linked entities are listed in the dictionary, hence the counts do not necessarily sum up to `_total`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF_DICT = {\n",
    "    '1992 elections': {\n",
    "        'wikipedia:Philippine_general_election,_1992': 9,\n",
    "        'wikipedia:Angolan_presidential_election,_1992': 1,\n",
    "        '_total': 98\n",
    "    },\n",
    "    'angola': {\n",
    "        'wikipedia:Angola': 4026,\n",
    "        'wikipedia:Angola_(Portugal)': 6,\n",
    "        'wikipedia:Angola_national_football_team': 120,\n",
    "        '_total': 4298\n",
    "    },\n",
    "    'democracy': {\n",
    "        'wikipedia:Democracy': 108,\n",
    "        'wikipedia:Democracy_(album)': 3,\n",
    "        '_total': 2162\n",
    "    },\n",
    "    'multiparty democracy': {\n",
    "        'wikipedia:multiparty_democracy': 11,\n",
    "        '_total': 11\n",
    "    },\n",
    "    'one party': {\n",
    "        'wikipedia:Non-possessors': 1,\n",
    "        'wikipedia:Single-party_state': 5,\n",
    "        '_total': 983\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = (\n",
    "    'Angola changed from a one-party Marxist-Leninist system '\n",
    "    'ruled by the MPLA to a formal multiparty democracy '\n",
    "    'following the 1992 elections'\n",
    ").lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform mention detection based on the following heuristic:\n",
    "\n",
    "  - At each term position\n",
    "    - Start with the longest possible n-gram (n = 8). \n",
    "    - If the n-gram is found in the dictionary, the mention and the corresponding entities are kept (and the shorter n-grams are ignored). Otherwise, we try to match the (n-1)-grams. \n",
    "    - Repeat until a mention is found or n reaches 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_mentions(text, sf_dict):\n",
    "    \"\"\"Performs mention detection in text against a given surface form dictionary.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text.\n",
    "        sf_dict: Surface form dictionary.\n",
    "    \n",
    "    Returns:\n",
    "        List of matches as `(pos, mention, entity)` tuples ordered by pos, mention, and entity.\n",
    "        (Term positions are indexed from 0.)\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    tokens = text.split()\n",
    "    for pos, term in enumerate(tokens):\n",
    "        n = max(8, len(tokens) - pos)\n",
    "        while n > 0:\n",
    "            # Check for matching n-gram\n",
    "            n_gram = ' '.join(tokens[pos:pos+n])\n",
    "            if n_gram in sf_dict:\n",
    "                for entity in sorted(sf_dict[n_gram].keys()):\n",
    "                    if entity != '_total':\n",
    "                        matches.append((pos, n_gram, entity))\n",
    "                break\n",
    "            n -= 1\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                                  [100%]\n",
      "1 passed in 0.01s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_detect_mentions():\n",
    "    assert detect_mentions(TEXT, SF_DICT) == [\n",
    "        (0, 'angola', 'wikipedia:Angola'),\n",
    "        (0, 'angola', 'wikipedia:Angola_(Portugal)'),\n",
    "        (0, 'angola', 'wikipedia:Angola_national_football_team'),\n",
    "        (14, 'multiparty democracy', 'wikipedia:multiparty_democracy'),\n",
    "        (15, 'democracy', 'wikipedia:Democracy'),\n",
    "        (15, 'democracy', 'wikipedia:Democracy_(album)'),\n",
    "        (18, '1992 elections', 'wikipedia:Angolan_presidential_election,_1992'),\n",
    "        (18, '1992 elections', 'wikipedia:Philippine_general_election,_1992')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Entity ranking\n",
    "\n",
    "Entity ranking is based on the commonness score:\n",
    "\n",
    "$$Commonness(e, m) = p(e|m) = \\frac{n(m, e)}{\\sum_{e'} n(m, e')}$$\n",
    "\n",
    "where $n(m, e)$ denotes the number of times entity $e$ is the link target of mention $m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commonness(entity, mention, sf_dict):\n",
    "    \"\"\"Computes the commonness for an entity-mention pair given a surface form dictionary.\n",
    "    \n",
    "    Args:\n",
    "        entity: Entity.\n",
    "        mention: Mention.\n",
    "        sf_dict: Surface form dictionary (containing entity-mention count statistics).\n",
    "        \n",
    "    Returns:\n",
    "        Commonness (float).    \n",
    "    \"\"\"\n",
    "    if mention not in sf_dict:\n",
    "        return None\n",
    "    return sf_dict[mention].get(entity, 0) / sf_dict[mention]['_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_entities(mentions, sf_dict, k=5):\n",
    "    \"\"\"Ranks candidate entities for each mention based on commonness and retains \n",
    "    the top-k highest-scoring entities for each mention.\n",
    "    \n",
    "    Args:\n",
    "        mentions: Detected mentions (list of `(mention, entity, pos)` tuples).\n",
    "        sf_dict: Surface form dictionary.\n",
    "        k: Number of top-scoring entities to keep for each mention.\n",
    "        \n",
    "    Returns:\n",
    "        Candidate entities with scores for each mention. Each mention is \n",
    "        represented as a dict `{'mention': xxx, 'pos': yyy, 'entities': zzz`,\n",
    "        where entities is a list of `(entity, score)` tuples ordered by score desc.\n",
    "    \"\"\"\n",
    "    # Reorganize input for more convenient processing.\n",
    "    entities_per_mention = {}\n",
    "    for (pos, mention, entity) in mentions:\n",
    "        key = '{}::{}'.format(pos, mention)\n",
    "        if key not in entities_per_mention:\n",
    "            entities_per_mention[key] = []\n",
    "        entities_per_mention[key].append(entity)\n",
    "    \n",
    "    # Score all candidate entities for each mention.\n",
    "    mentions_entities = []\n",
    "    for key, entities in entities_per_mention.items():\n",
    "        pos, mention = key.split('::')\n",
    "        entity_scores = sorted([(entity, commonness(entity, mention, sf_dict))\n",
    "                               for entity in entities], key=lambda x: x[1], reverse=True)\n",
    "        mentions_entities.append({\n",
    "            'mention': mention,\n",
    "            'pos': int(pos),\n",
    "            'entities': entity_scores[:k]\n",
    "        })\n",
    "    return mentions_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........                                                                           [100%]\n",
      "8 passed in 0.03s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "@pytest.mark.parametrize(\"mention,entity,correct_value\", [\n",
    "    ('1992 elections', 'wikipedia:Philippine_general_election,_1992', 9/98),\n",
    "    ('1992 elections', 'wikipedia:Angolan_presidential_election,_1992', 1/98),\n",
    "    ('angola', 'wikipedia:Angola', 4026 / 4298),\n",
    "    ('angola', 'wikipedia:Angola_national_football_team', 120 / 4298),\n",
    "    ('democracy', 'wikipedia:Democracy', 108/2162),\n",
    "    ('democracy', 'wikipedia:Democracy_(album)', 3/2162),\n",
    "    ('multiparty democracy', 'wikipedia:multiparty_democracy', 1)    \n",
    "])\n",
    "def test_commonness(entity, mention, correct_value):    \n",
    "    assert commonness(entity, mention, SF_DICT) == pytest.approx(correct_value, rel=1e-3)\n",
    "    \n",
    "def test_rank_entities():\n",
    "    mentions = detect_mentions(TEXT, SF_DICT)\n",
    "    ranked_entities = rank_entities(mentions, SF_DICT, k=2)\n",
    "    assert ranked_entities[0] == {'mention': 'angola',\n",
    "                                  'pos': 0,\n",
    "                                  'entities': [\n",
    "                                      ('wikipedia:Angola', 0.9367147510469986),\n",
    "                                      ('wikipedia:Angola_national_football_team', 0.02791996277338297)\n",
    "                                  ]\n",
    "                                 }\n",
    "    assert ranked_entities[1] == {'mention': 'multiparty democracy',\n",
    "                                  'pos': 14,\n",
    "                                  'entities': [('wikipedia:multiparty_democracy', 1.0)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Disambiguation\n",
    "\n",
    "Perform disambiguation by simply returning the entity for each mention with the highest score and only if it is above the given threshold.\n",
    "\n",
    "In case of containment or overlapping mentions, keep only the one with the higher score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguate(ranked_entities, threshold=0.1):\n",
    "    \"\"\"Disambiguates entities for each mention by keeping only the highest-scoring one.\n",
    "    \n",
    "    Args:\n",
    "        ranked_entities: List of mentions along with a ranked list of candidate entities.\n",
    "        threshold: Score threshold\n",
    "    \n",
    "    Returns:\n",
    "        Entity annotations as a list of `(pos, mention, entity)` tuples.\n",
    "    \"\"\"\n",
    "    # For each term position, we keep track of the highest scoring entity\n",
    "    # that is linked to a mention in that position. We can greedily replace \n",
    "    # the annotations in case a higher scoring one is found.\n",
    "    annotations = {}\n",
    "    for candidates in ranked_entities:\n",
    "        (entity, score) = candidates['entities'][0]\n",
    "        if score < threshold:\n",
    "            continue\n",
    "        start_pos = candidates['pos']\n",
    "        mention = candidates['mention']\n",
    "        mention_length = len(mention.split())\n",
    "        # Add mention-entity annotation if all term positions are\n",
    "        # empty or are lower scoring.\n",
    "        add_annotation = True\n",
    "        for pos in range(start_pos, start_pos + mention_length):\n",
    "            if pos in annotations:\n",
    "                if annotations[pos]['score'] > score:\n",
    "                    add_annotation = False\n",
    "        \n",
    "        if add_annotation:\n",
    "            # For each term position, check if there is an existing \n",
    "            # annotation to be replaced.\n",
    "            for pos in range(start_pos, start_pos + mention_length):\n",
    "                if pos in annotations:\n",
    "                    print(\"Replace on \", pos)\n",
    "                    # Replace existing annotation.\n",
    "                    start_pos_old = annotatations[pos]['start_pos']\n",
    "                    mention_length_old = annotatations[pos]['mention_length']\n",
    "                    for i in range(start_pos_old, start_pos_old + mention_length_old):\n",
    "                        del annotations[i]\n",
    "                \n",
    "                # Store new annotation.\n",
    "                annotations[pos] = {\n",
    "                    'score': score,\n",
    "                    'entity': entity,\n",
    "                    'mention': mention,\n",
    "                    'start_pos': start_pos,\n",
    "                    'mention_length': mention_length\n",
    "                }\n",
    "\n",
    "    # Converting output to desired format.\n",
    "    linked_entities = []\n",
    "    for pos, annotation in sorted(annotations.items()):\n",
    "        if pos == annotation['start_pos']:\n",
    "            linked_entities.append((pos, annotation['mention'], annotation['entity']))    \n",
    "    return linked_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                                  [100%]\n",
      "1 passed in 0.01s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_disambiguate():\n",
    "    mentions = detect_mentions(TEXT, SF_DICT)\n",
    "    ranked_entities = rank_entities(mentions, SF_DICT)\n",
    "    linked_entities = disambiguate(ranked_entities, threshold=0.01)\n",
    "    assert linked_entities == [\n",
    "        (0, 'angola', 'wikipedia:Angola'),\n",
    "        (14, 'multiparty democracy', 'wikipedia:multiparty_democracy'),\n",
    "        (18, '1992 elections', 'wikipedia:Philippine_general_election,_1992')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "\n",
    "Please give (anonymous) feedback on this exercise by filling out [this form](https://forms.gle/2jPayczbFhEcC9K68)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
